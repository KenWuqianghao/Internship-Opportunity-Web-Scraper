{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "14e81b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c616608f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"URL Template\"\"\"\n",
    "headers = {\"User-Agent\": \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10.14; rv:66.0) Gecko/20100101 Firefox/66.0\", \"Accept\": \"text/html,application/xhtml+xml,application/xml;q=0.9,*/*;q=0.8\", \"Accept-Language\": \"en-US,en;q=0.5\", \"Accept-Encoding\": \"gzip, deflate\", \"DNT\": \"1\", \"Connection\": \"close\", \"Upgrade-Insecure-Requests\": \"1\"}\n",
    "\n",
    "url_temp= \"https://indeed.com/jobs?q={}&l={}\"\n",
    "base_link=\"https://indeed.com\"\n",
    "\n",
    "\"\"\"This function takes the URL template, designation and city as inputs.\n",
    "It navigates through the top 200 search results and scans all the <a> tags and returns a list of \n",
    "all the href attributes.\"\"\"\n",
    "\n",
    "def get_href(url_temp,position,city):\n",
    "    href_list=[]\n",
    "    url=url_temp.format(position,city)\n",
    "    r=requests.get(url,headers=headers)\n",
    "    soup=BeautifulSoup(r.text,\"html.parser\")    \n",
    "\n",
    "    for i in soup.find_all('a'):\n",
    "        # if tag has attribute of class\n",
    "        if i.has_attr( \"href\" ):\n",
    "            k=i['href']\n",
    "            href_list.append(base_link+k)\n",
    "    \n",
    "    return href_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8d7d0532",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function takes the list of all the href attributes as input, \n",
    "finds the URLs with the mentioned strings and returns a list of those URLs.\"\"\"\n",
    "\n",
    "def get_job_links(href_list):\n",
    "    job_links=[]\n",
    "    for a in href_list:\n",
    "        if a.find('/rc/clk')!=-1:\n",
    "            job_links.append(a)\n",
    "        elif a.find('/company/')!=-1:\n",
    "            job_links.append(a)\n",
    "    return job_links"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "e28d9716",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"This function takes the list of the URLs of the job postings and the city and does the following:\n",
    "1. Send HTTP request to each of the URL.\n",
    "2. Creates a soup object with html parsing.\n",
    "3. Extracts title, company name, location and job description from each of the webpage and returns a dataframe.\"\"\"\n",
    "\n",
    "def get_job_df(job_links,city):\n",
    "    df=pd.DataFrame(columns=[\"job_location\", \"job_title\", \"company\", \"job_description\"])\n",
    "    \n",
    "    for i in job_links:\n",
    "        req=requests.get(i,headers=headers)\n",
    "        soup_req=BeautifulSoup(req.text,\"html.parser\")\n",
    "        try:\n",
    "            title=soup_req.find('h1',{'class': 'icl-u-xs-mb--xs icl-u-xs-mt--none jobsearch-JobInfoHeader-title'}).text\n",
    "        except:\n",
    "            continue\n",
    "        try:\n",
    "            company=soup_req.find('div',{'class':'icl-u-lg-mr--sm icl-u-xs-mr--xs'}).text\n",
    "        except:\n",
    "            continue\n",
    "        try:\n",
    "            location=soup_req.find('div',{'class':'jobsearch-InlineCompanyRating icl-u-xs-mt--xs jobsearch-DesktopStickyContainer-companyrating'}).text\n",
    "        except:\n",
    "            location=city\n",
    "        try:\n",
    "            desc=soup_req.find('div',{'class':'jobsearch-jobDescriptionText'}).text\n",
    "        except:\n",
    "            continue\n",
    "        df = df.append({\"job_location\":city, \"job_title\":title, \"company\":company, \"job_description\":desc},\n",
    "                       ignore_index=True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "035f1f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Calling all the above functions inside this function which takes the URL template, designation and city as inputs.\"\"\"\n",
    "\n",
    "def get_job_postings(url_temp,position,city):\n",
    "    \n",
    "    href_list= get_href(url_temp,position,city)\n",
    "    \n",
    "    job_links= get_job_links(href_list)\n",
    "    \n",
    "    job_df= get_job_df(job_links,city)\n",
    "    \n",
    "    return job_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "0981d52b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>job_location</th>\n",
       "      <th>job_title</th>\n",
       "      <th>company</th>\n",
       "      <th>job_description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [job_location, job_title, company, job_description]\n",
       "Index: []"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "highschool_df= get_job_postings(url_temp,position='High+School+Internship',city='Remote')\n",
    "highschool_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "84d61de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "highschool_df.to_csv('indeed_intern.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
